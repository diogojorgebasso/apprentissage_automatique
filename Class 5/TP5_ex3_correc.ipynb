{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'apprentissage automatique: TP5 - Exercice 3 - <font color=red> CORRECTION </font>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Prédiction de la qualité de vins\n",
    "\n",
    "Le dataset suivant:\n",
    "\n",
    "https://www.openml.org/d/40691\n",
    "\n",
    "fournit la description de 1599 vins rouges: 12 mesures physico-chimiques ainsi qu'un critère qualitatif donné comme une note entre 3 et 8 (plus haute est la note, meilleur est le vin).\n",
    "\n",
    "Remarquez que les 12 caractéristiques doivent être normalisées.\n",
    "\n",
    "La cellule suivante charge les données, construit des bases d'apprentissage et de test, et normalise les caractéristiques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics, neural_network, svm, model_selection, preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# chargement des données\n",
    "X_wine, y_wine = datasets.fetch_openml('wine-quality-red', return_X_y=True, as_frame=False, parser='auto')\n",
    "\n",
    "n_samples = len(X_wine)\n",
    "print(\"nombre total d'observations (apprentissage + test): %d\" % n_samples)\n",
    "\n",
    "n_features = len(X_wine[0])\n",
    "print(\"nombre de caractéristiques par observation: %d\" % n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_wine, y_wine, test_size=0.3, random_state=1)\n",
    "\n",
    "print(\"nombre d'observations dans la base d'apprentissage: %d\" %len(X_train))\n",
    "print(\"nombre d'observations dans la base de test: %d\" %len(X_test))\n",
    "\n",
    "print(\"\\n Cinq premières observations de X_train:\")\n",
    "print(X_train[:5,:])\n",
    "print(\"\\n et classes associées:\")\n",
    "print(y_train[:5])\n",
    "\n",
    "# normalisation:\n",
    "X_train_n = preprocessing.StandardScaler().fit_transform(X_train)\n",
    "X_test_n = preprocessing.StandardScaler().fit(X_train).transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux remarques:\n",
    "\n",
    "- Certaines caractéristiques semblent corrélées (on pourrait le vérifier en traçant des graphiques et en calculant des coefficients de corrélation comme dans le cours d'analyse de données): il serait sans doute pertinent de sélectionner des caractéristiques ou de réduire la dimension des observations.\n",
    "\n",
    "- Nous allons envisager ce problème comme un problème de classification à 6 classes (les notes de 3 à 8). Néanmoins, il ne semblerait pas absurde de l'envisager comme un problème de régression.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Proposez des prédicteurs de la qualité en fonction des 12 mesures physico-chimiques. Vous explorerez les machines à vecteurs supports et les perceptrons multicouches, dont vous fixerez les hyperparamètres par _grid search_ et validation croisée.\n",
    "\n",
    "<br>\n",
    "\n",
    "Comparez vos résultats à ceux reportés ici:\n",
    "https://www.openml.org/t/146217\n",
    "(en vous demandant si les valeurs sont bien comparables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non demandé\n",
    "#############\n",
    "# visualisation des scatter-plot d'une variable contre une autre\n",
    "# on constate que certaines variables sont bien liées à d'autres\n",
    "import pandas\n",
    "import seaborn\n",
    "data = datasets.fetch_openml('wine-quality-red', return_X_y=False, as_frame=True, parser='auto')\n",
    "data_df = pandas.DataFrame(data.data, columns=data.feature_names)\n",
    "seaborn.pairplot(data_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choix de C et gamma pour SVM et noyau gaussien  \n",
    "C_range=10**(np.arange(-3.,3.5,.5))   \n",
    "gamma_range=10**(np.arange(-3,3.5,.5))\n",
    "parameters = { 'C':C_range, 'gamma':gamma_range }\n",
    "SVM = svm.SVC(kernel='rbf')\n",
    "\n",
    "gridsearch_SVM = model_selection.GridSearchCV(SVM, parameters,n_jobs=-1)\n",
    "\n",
    "%time gridsearch_SVM.fit(X_train_n,y_train)\n",
    "print(\"Avec normalisation, meilleur estimateur trouvé:\")\n",
    "print(gridsearch_SVM.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inutile de ré-entraîner: par défaut gridsearch.fit finit par l'entraînement du meilleur modèle sélectionné par validation croisée\n",
    "# SVM=svm.SVC(kernel='rbf',C=3.16,gamma=0.32)  \n",
    "# SVM.fit(X_train_n,y_train)\n",
    "# print(\"score SVM %.3f\" % SVM.score(X_test_n, y_test) )\n",
    "\n",
    "print(\"score SVM %.3f\" % gridsearch_SVM.score(X_test_n, y_test) )\n",
    "\n",
    "metrics.confusion_matrix(y_test, gridsearch_SVM.predict(X_test_n)) \n",
    "# remarque: globalement les valeurs sont regroupées autour de la diagonale de la matrice de confusion\n",
    "# (sauf pour les notes 3 et 8) \n",
    "# ce qui est bon signe: quand on se trompe de classe on ne décale que d'une ou deux notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_range=10**(np.arange(-6.,0.,2))\n",
    "n_neurons_range=((10,), (50,), (100,), (10,10), (50,50))\n",
    "max_iter_range=(10, 50, 100, 200)\n",
    "parameters={ 'alpha':alpha_range, 'hidden_layer_sizes':n_neurons_range, 'max_iter':max_iter_range}\n",
    "MLP = neural_network.MLPClassifier(parameters, random_state=1)\n",
    "\n",
    "gridsearch_MLP = model_selection.GridSearchCV(MLP, parameters,n_jobs=-1)\n",
    "\n",
    "%time gridsearch_MLP.fit(X_train_n,y_train)\n",
    "print(\"Avec normalisation, meilleur estimateur trouvé:\")\n",
    "print(gridsearch_MLP.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#MLP=neural_network.MLPClassifier(alpha=1e-2, hidden_layer_sizes=(50,50), max_iter=100, random_state=1, verbose=true)  \n",
    "#MLP.fit(X_train_n,y_train)\n",
    "\n",
    "print(\"score MLP %.3f\" % gridsearch_MLP.score(X_test_n, y_test) )\n",
    "metrics.confusion_matrix(y_test, gridsearch_MLP.predict(X_test_n)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "\n",
    "Les matrices de confusion montrent que lorsqu'on se trompe, c'est généralement en prédisant un score proche du \"vrai\" score.\n",
    "    \n",
    "La SVM semble fournir des résultats un peu meilleurs (score de 0.613 contre 0.571 sur la base test)\n",
    "    \n",
    "Remarquons qu'une telle valeur de score pour un problème de classification à 6 classes n'est pas si mauvaise: si on prédisait au hasard on obtiendrait un score de 1/6 = 0.16. Si on prédisait systématiquement la classe de plus grand cardinal (note 5:  681 observations sur 1599), le score serait 0.43. \n",
    "    \n",
    "Cela nous met dans le haut du panier des méthodes rassemblées ici:\n",
    "    https://www.openml.org/t/146217\n",
    "(voir `Analysis` puis sélectionner `predictive accuracy`)\n",
    "    \n",
    "Attention néanmoins, le score de la page openml est un score de 10-fold cross validation. Il faudrait comparer au score de la cellule suivante (encore que je ne suis pas certain de la normalisation utilisée dans les résultats d'openml):\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X_wine, y_wine = datasets.fetch_openml('wine-quality-red', return_X_y=True,parser='auto')\n",
    "X_wine_n = preprocessing.StandardScaler().fit_transform(X_wine)\n",
    "SVM=svm.SVC(kernel='rbf',C=3.16,gamma=0.32)  \n",
    "scores = cross_val_score(SVM, X_wine_n, y_wine, cv=10)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
