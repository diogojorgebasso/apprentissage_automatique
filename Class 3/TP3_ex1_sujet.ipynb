{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3 - Exercice 1\n",
    "\n",
    "<br>\n",
    "\n",
    "## Détection de spam\n",
    "\n",
    "<br>\n",
    "\n",
    "Dans ce TP, nous allons entraîner des classifieurs pour décider si un mail est un spam ou non.\n",
    "\n",
    "<br>\n",
    "\n",
    "Tout d'abord, quelques indications sur l'utilisation des méthodes d'apprentissage de `scikit-learn`.\n",
    "\n",
    "Les méthodes d'apprentissage supervisé de `scikit-learn` permettent de définir un objet, doté de différents attributs et méthodes, dont `cross_val_score` (pour calculer un score de validation croisée), `fit` (pour procéder à l'apprentissage), `predict` (pour prédire les classes des éléments d'une base de test), ou `score` pour calculer la proportion d'observations bien classées dans la base de test, sur laquelle on peut comparer la classe prédite à la \"vraie\" classe.\n",
    "\n",
    "Ci-dessous, un exemple d'utilisation de la classification au plus proche voisin, dans un scénario où on suppose disposer d'une base d'apprentissage $(X_{train},y_{train})$, et d'une base de test $X_{test}$ pour laquelle on connaît $y_{test}$, de manière à valider l'apprentissage sur la base de test. Si on veut changer de classifieur, il suffit d'utiliser un autre constructeur que `neighbors.KNeighborsClassifier` et de passer les paramètres adéquats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (le code suivant ne peut pas être exécuté \"tel quel\"...)\n",
    "\n",
    "# classifieur au plus proche voisin (on peut changer le paramètre n_neighbors):\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)  \n",
    "\n",
    "# calcul d'un score moyen de validation croisée \"à 5 plis\" sur (X_train,y_train)\n",
    "scores = cross_val_score(knn,X_train,y_train,cv=5)\n",
    "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(),2*scores.std()))\n",
    "\n",
    "# la prédiction d'une nouvelle observation consistera à chercher le p.p.v. dans X_train, \n",
    "# et à associer la classe de ce p.p.v., donnée par y_train:\n",
    "knn.fit(X_train,y_train)  \n",
    "# Remarque: il n'y a pas d'apprentissage à proprement parler pour les p.p.v., \n",
    "# il s'agit juste de préciser la base dans laquelle seront cherchés les plus proches voisins\n",
    "\n",
    "# on stocke dans y_pred les classes prédites sur un ensemble de test X_test:\n",
    "y_pred = knn.predict(X_test)  \n",
    "\n",
    "# calcul d'un score lorsqu'on connaît les vraies classes des observations de X_test: \n",
    "# (proportion d'observations pour lesquelles y_test==y_pred)\n",
    "score = knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Préliminaires\n",
    "\n",
    "<br>\n",
    "\n",
    "Commençons par charger les bibliothèques utiles au TD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn import neighbors, linear_model, naive_bayes, metrics\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, on charge les données: récupérez au préalable le fichier `spambase.data` disponible sur le [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Spambase) (cliquez sur \"Download\"). La description complète de la base est dans le fichier `spambase.name`, à ouvrir avec un éditeur de texte.\n",
    "\n",
    "<br>\n",
    "\n",
    "La cellule suivante charge les données. On forme une base d'entraînement avec 80% des données (choix aléatoire), et on garde 20% des données pour faire une base de test. Dans la cellule suivante, on fixe la graîne du générateur aléatoire (`random_state=1`, la valeur est arbitraire) de manière à ce que l'on ait tous les mêmes résultats afin de faciliter la comparaison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:\n",
      "[[0.000e+00 6.400e-01 6.400e-01 ... 6.100e+01 2.780e+02 1.000e+00]\n",
      " [2.100e-01 2.800e-01 5.000e-01 ... 1.010e+02 1.028e+03 1.000e+00]\n",
      " [6.000e-02 0.000e+00 7.100e-01 ... 4.850e+02 2.259e+03 1.000e+00]\n",
      " ...\n",
      " [3.000e-01 0.000e+00 3.000e-01 ... 6.000e+00 1.180e+02 0.000e+00]\n",
      " [9.600e-01 0.000e+00 0.000e+00 ... 5.000e+00 7.800e+01 0.000e+00]\n",
      " [0.000e+00 0.000e+00 6.500e-01 ... 5.000e+00 4.000e+01 0.000e+00]]\n",
      "\n",
      "TOTAL - nombre d'observations, nombre de caractéristiques:\n",
      "(4601, 58)\n",
      "\n",
      "APPRENTISSAGE - nombre d'observations, nombre de caractéristiques:\n",
      "(3680, 57)\n",
      "\n",
      "APPRENTISSAGE - nombre de labels associés aux obervations:\n",
      "(3680,)\n",
      "\n",
      "TEST - nombre d'observations, nombre de caractéristiques:\n",
      "(921, 57)\n",
      "\n",
      "TEST - nombre de labels associés aux obervations:\n",
      "(921,)\n",
      "\n",
      "observations, base d'apprentissage:\n",
      "[[0.000e+00 0.000e+00 0.000e+00 ... 2.307e+00 9.000e+00 3.000e+01]\n",
      " [8.000e-02 1.700e-01 1.700e-01 ... 2.658e+00 5.700e+01 4.360e+02]\n",
      " [0.000e+00 0.000e+00 1.850e+00 ... 1.727e+00 5.000e+00 1.900e+01]\n",
      " ...\n",
      " [0.000e+00 0.000e+00 7.600e-01 ... 2.441e+00 1.900e+01 2.490e+02]\n",
      " [0.000e+00 0.000e+00 8.700e-01 ... 1.601e+00 1.100e+01 2.770e+02]\n",
      " [0.000e+00 0.000e+00 0.000e+00 ... 1.103e+00 3.000e+00 3.200e+01]]\n",
      "\n",
      "labels associés, base d'apprentissage:\n",
      "[0. 0. 0. ... 1. 0. 1.]\n",
      "\n",
      "proportion de spams dans la base d'apprentissage:\n",
      "0.39565217391304347\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('spambase.data', delimiter=',')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[:,:-1], data[:,-1], test_size=0.2, random_state=1)\n",
    "# pour vérifier que les données sont bien chargées:\n",
    "print(\"dataset:\")\n",
    "print(data)  \n",
    "print(\"\\nTOTAL - nombre d'observations, nombre de caractéristiques:\")\n",
    "print(data.shape)\n",
    "print(\"\\nAPPRENTISSAGE - nombre d'observations, nombre de caractéristiques:\")\n",
    "print(X_train.shape)\n",
    "print(\"\\nAPPRENTISSAGE - nombre de labels associés aux obervations:\")\n",
    "print(y_train.shape)\n",
    "print(\"\\nTEST - nombre d'observations, nombre de caractéristiques:\")\n",
    "print(X_test.shape)\n",
    "print(\"\\nTEST - nombre de labels associés aux obervations:\")\n",
    "print(y_test.shape)\n",
    "print(\"\\nobservations, base d'apprentissage:\")\n",
    "print(X_train)\n",
    "print(\"\\nlabels associés, base d'apprentissage:\")\n",
    "print(y_train)\n",
    "print(\"\\nproportion de spams dans la base d'apprentissage:\")\n",
    "print(np.mean(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1__. A partir de la description de la base de données, justifiez la manière employée pour charger les données en `X` (observations) et `y` (labels). Quelles sont les caractéristiques des observations, les labels, et quel est le rapport avec le problème initial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "  \n",
    "As características    \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarque importante__: lorsqu'on teste des classifieurs, il est important de comparer les scores de classification obtenus à celui d'un \"dummy classifier\" (un classifieur fictif): un classifieur qui fait une prévision sans tenir compte des observations. Par exemple, ici un classifieur qui classerait toute observation comme \"non spam\" aurait raison dans presque 60% des cas. On espère donc que les classifieurs réels soient meilleurs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification aux plus proches voisins\n",
    "\n",
    "<br>\n",
    "\n",
    "Mettez en oeuvre les classifications au plus proche voisin et aux 5 plus proches voisins. Vous calculerez le score moyen de validation croisée à 5 plis sur la base d'apprentissage ainsi que le score obtenu sur la base de test. Vous vous inspirerez du code détaillé en introduction. \n",
    "\n",
    "__Question 2__. Quelle est la métrique utilisée pour déterminer les plus proches voisins? Quel est ce \"score\" calculé exactement? Quel lien entre score de validation croisée et score sur la base de test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score moyen de validation croisée: 0.809 (+/- 0.013)\n",
      "score: 0.801\n"
     ]
    }
   ],
   "source": [
    "# votre code ici pour 1-ppv:\n",
    "print()\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "scores = cross_val_score(knn, X_train, y_train)\n",
    "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(), 2*scores.std()))\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "score = knn.score(X_test, y_test)\n",
    "print(\"score: %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O KNN ele só calcula a distância. É pré-processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "score moyen de validation croisée: 0.795 (+/- 0.029)\n",
      "score: 0.798\n"
     ]
    }
   ],
   "source": [
    "# votre code ici pour 5-ppv:\n",
    "print()\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(knn, X_train, y_train)\n",
    "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(), 2*scores.std()))\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "score = knn.score(X_test, y_test)\n",
    "print(\"score: %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "\n",
    "A métrica é o score.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3__. Pourquoi la métrique utilisée n'est-elle pas adaptée aux observations ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "\n",
    "Porque \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4__. Pré-traitez les données par standardisation, comme expliqué ici sur [la documentation scikit-learn](https://scikit-learn.org/stable/modules/preprocessing.html) (utilisez `StandardScaler` de manière à utiliser la même normalisation sur la base d'apprentissage et sur la base de test, c'est important), puis recalculez les scores des deux classifieurs précédents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score moyen de validation croisée: 0.902 (+/- 0.021)\n",
      "score: 0.911\n",
      "score moyen de validation croisée: 0.898 (+/- 0.011)\n",
      "score: 0.911\n"
     ]
    }
   ],
   "source": [
    "# votre code:\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_standard = scaler.transform(X_train)\n",
    "Y_test_standardized = scaler.transform(X_test)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "scores = cross_val_score(knn, X_train_standard, y_train)\n",
    "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(), 2*scores.std()))\n",
    "knn.fit(X_train_standard, y_train)\n",
    "y_pred = knn.predict(Y_test_standardized)\n",
    "score = knn.score(Y_test_standardized, y_test)\n",
    "print(\"score: %0.3f\" % score)\n",
    "\n",
    "KNN5 = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(KNN5, X_train_standard, y_train)\n",
    "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(), 2*scores.std()))\n",
    "KNN5.fit(X_train_standard, y_train)\n",
    "y_pred = KNN5.predict(Y_test_standardized)\n",
    "score = KNN5.score(Y_test_standardized, y_test)\n",
    "print(\"score: %0.3f\" % score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classifieur naïf de Bayes gaussien et classifieur de la régression logistique\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "__Question 5__. Pourquoi le classifieur naïf de Bayes gaussien ne nécessite-t-il pas de standardisation préalable des données ? (vous pouvez vérifier que la normalisation joue tout de même un faible rôle: elle a sans doute une influence sur le comportement de l'algorithme d'estimation des paramètres).\n",
    "\n",
    "\n",
    "Mettez en oeuvre le classifieur naïf de Bayes gaussien (lisez le début de la [documentation](https://scikit-learn.org/stable/modules/naive_bayes.html) où vous retrouverez le contenu du cours, puis la syntaxe de `GaussianNB` [ici](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifieur naïf de Bayes gaussien (sur les données originales):\n",
      "score moyen de validation croisée: 0.825 (+/- 0.021)\n",
      "score: 0.817\n"
     ]
    }
   ],
   "source": [
    "# votre code pour le classifieur naïf de Bayes gaussien (sur les données originales):\n",
    "print(\"classifieur naïf de Bayes gaussien (sur les données originales):\")\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "scores = cross_val_score(gnb, X_train, y_train)\n",
    "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(), 2*scores.std()))\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "score = gnb.score(X_test, y_test)\n",
    "print(\"score: %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mettez en oeuvre le classifieur de la régression logistique ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)). \n",
    "\n",
    "Passez l'option `max_iter=2000` si vous avez un avertissement concernant la convergence de l'optimisation, de la manière suivante:\n",
    "`LR = linear_model.LogisticRegression(max_iter=2000)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "régression logistique (sur les données standardisées):\n",
      "meilleur estimateur:  LogisticRegression(C=10, max_iter=2000)\n",
      "[0.90679348 0.91711957 0.925      0.92771739 0.92717391 0.9263587\n",
      " 0.92608696 0.92663043]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification par regression logistique\n",
      "score moyen de validation croisée: 0.925 (+/- 0.023)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [921, 3680]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore moyen de validation croisée: \u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124m (+/- \u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (scores\u001b[38;5;241m.\u001b[39mmean(), \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mscores\u001b[38;5;241m.\u001b[39mstd()))\n\u001b[0;32m     20\u001b[0m logreg\u001b[38;5;241m.\u001b[39mfit(X_train_standard, y_train)\n\u001b[1;32m---> 21\u001b[0m score_LR \u001b[38;5;241m=\u001b[39m \u001b[43mlogreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_standard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore: \u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m score_LR)\n\u001b[0;32m     23\u001b[0m y_pred_lr \u001b[38;5;241m=\u001b[39m logreg\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\diogo\\miniconda3\\envs\\ia\\Lib\\site-packages\\sklearn\\base.py:764\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 764\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\diogo\\miniconda3\\envs\\ia\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\diogo\\miniconda3\\envs\\ia\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\diogo\\miniconda3\\envs\\ia\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\diogo\\miniconda3\\envs\\ia\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [921, 3680]"
     ]
    }
   ],
   "source": [
    "# votre code pour la régression logistique (sur les données standardisées):\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"régression logistique (sur les données standardisées):\")\n",
    "logreg = linear_model.LogisticRegression(max_iter=2000)\n",
    "GS = GridSearchCV(logreg, {'C': [0.01, 0.1, 1, 10, 100, 1000, 100000, 1000000]}, cv=5)\n",
    "GS.fit(X_train_standard, y_train)\n",
    "print(\"meilleur estimateur: \", GS.best_estimator_)\n",
    "print(GS.cv_results_[\"mean_test_score\"])\n",
    "plt.figure()\n",
    "plt.plot([0.01, 0.1, 1, 10, 100, 1000, 100000, 1000000], GS.cv_results_[\"mean_test_score\"])\n",
    "plt.xscale(\"log\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification par regression logistique\")\n",
    "logreg = linear_model.LogisticRegression(max_iter=2000, C=1)\n",
    "scores = cross_val_score(logreg, X_train_standard, y_train)\n",
    "print(\"score moyen de validation croisée: %0.3f (+/- %0.3f)\" % (scores.mean(), 2*scores.std()))\n",
    "logreg.fit(X_train_standard, y_train)\n",
    "score_LR = logreg.score(X_test_standard, y_test)\n",
    "print(\"score: %0.3f\" % score_LR)\n",
    "y_pred_lr = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse des résultats\n",
    "\n",
    "<br>\n",
    "\n",
    "On dispose des matrices de confusion, décrites [ici](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html), et des rapports de classification, décrits [là](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n",
    "\n",
    "__Question 6__. Affichez ces matrices et rapports sur la base test pour les quatre classifieurs étudiés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre code ici:\n",
    "p = 0.6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 7__. Ici, par quoi pourraient s'expliquer les performances modestes du classifieur naïf de Bayes ?\n",
    "A ce stade, quel classifieur préfére-t-on et pourquoi? Dans une application de détection de spams, cherche-t-on réellement à minimiser le taux d'erreur global?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "       \n",
    "Réponse:\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Toutes les erreurs ne se valent pas...\n",
    "\n",
    "Le classifieur bayésien naïf gaussien et le classifieur de la régression logistique s'appuient tous deux sur la règle du maximum a posteriori. Ils permettent d'estimer la probabilité a posteriori $p(C_1|x)$ et détectent un spam lorsque $p(C_1|x)>1/2$, où $C_1$ désigne la classe \"spam\" et $x$ est une observation. Les deux classifieurs mettent en oeuvre le classifieur de Bayes, qui minimise le risque moyen de prédiction (le taux d'erreur).  Le taux d'erreur \"compte\" de la même manière les erreurs sur les deux classes.\n",
    "\n",
    "Si on préfère réduire le taux de faux positif de la méthode (proportion de mails détectés à tort comme \"spam\"), on peut relever le seuil de cette probabilité. \n",
    "\n",
    "Les classifieurs `LogisticRegression` et `GaussianNB` possèdent tous deux une méthode `predict_proba` qui, pour un tableau d'observations, fournit la probabilité a posteriori de chaque classe, comme l'affiche la cellule suivante. On remarque que pour chaque observation $x$, $p(C_0|x)+p(C_1|x)=1$.  (attention, la documentation n'est pas très claire, `predict_proba` fournit bien la probabilité a posteriori, et pas la vraisemblance $p(x|C_k)$)\n",
    "\n",
    "Remarquons qu'aucune probabilité n'est fournie par la classification aux plus proches voisins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"probabilités a posteriori pour GNB:\")\n",
    "print(GNB.predict_proba(X_test))\n",
    "print(\"\\nprobabilités a posteriori pour LR:\")\n",
    "print(LR.predict_proba(X_test_standard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faites varier le seuil de détection p:\n",
    "p=0.5  # constatez que p=0.5 fournit les mêmes résultats pour y_pred_lr et y_pred_LRb\n",
    "y_pred_LRb = (LR.predict_proba(X_test_standard)[:,1] >= p).astype(int)\n",
    "#print(y_pred_LRb)   # pour visualiser les classes prédites\n",
    "#print(y_pred_lr)\n",
    "score_LRb = 1-np.mean(np.abs(y_test-y_pred_LRb))  # calcul du taux de reconnaissance\n",
    "\n",
    "print(\"\\nClassification de la régression logistique pour un seuil de probabilité p=%.3f\" %p)\n",
    "print('score sur la base de test: %.3f' %score_LRb)\n",
    "print(metrics.classification_report(y_test,y_pred_LRb))\n",
    "print(\"matrice de confusion:\")\n",
    "print(metrics.confusion_matrix(y_test,y_pred_LRb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 8__. Quelle valeur du seuil de probabilité $p$ faut-il choisir pour assurer un rappel de la classe \"non spam\" d'au moins 0.98?\n",
    "Que penser de cet algorithme de détection de spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    \n",
    "Réponse:\n",
    "    \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
