{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'apprentissage automatique: TP additionnel\n",
    "\n",
    "<br>\n",
    "\n",
    "### Mélanges de gaussiennes et jeu de données \"Old Faithful\", prédiction par Gaussian Mixture Regression\n",
    "\n",
    "<br>\n",
    "On va étudier un jeu de données relatif au geyser \"Old Faithful\" dans le parc du Yellowstone aux Etats-Unis.\n",
    "\n",
    "Chaque observation est constituée de deux caractéristiques: la durée d'une éruption et la durée avant l'éruption suivante.\n",
    "\n",
    "\n",
    "Les données sont décrites ici: \n",
    "http://www.stat.cmu.edu/~larry/all-of-statistics/=data/faithful.dat <br>\n",
    "et doivent être téléchargées sur Arche ou [sur la page web du cours](https://members.loria.fr/FSur/enseignement/apprauto/old_faithful.txt).\n",
    "\n",
    "<br>\n",
    "On commence par charger les bibliothèques qui nous seront utiles:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn import mixture\n",
    "\n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "puis on charge les données du fichier `old_faithful.txt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention: le notebook doit être ouvert dans le même répertoire que le fichier old_faithful.txt\n",
    "data=np.loadtxt('old_faithful.txt')\n",
    "print(data)  # pour vérifier que les données sont bien chargées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par représenter les données par un nuage de point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[12,10]);\n",
    "plt.scatter(data[:,1], data[:,2]);\n",
    "plt.grid()\n",
    "plt.xlabel('durée éruption')\n",
    "plt.ylabel('temps avant la prochaine éruption')\n",
    "plt.title('Old Faithful');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation d'une densité de probabilité par mélange de gaussiennes\n",
    "\n",
    "Les observations sont des couples $(x,y)$ où $x$ est la durée d'éruption et $y$ le temps avant la prochaine éruption. Nous allons modéliser la loi jointe du couple $(x,y)$ à l'aide d'un mélange de gaussiennes.\n",
    "\n",
    "__Question 1__. Observez l'évolution du critère BIC dans l'ajustement d'un mélange de gaussiennes à $M$ composantes, pour $M$ variant entre 1 et 10 (inspirez-vous du code ci-dessous, et utilisez la [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)). Vous afficherez les lignes d'iso-valeur du logarithme de la densité de probabilité estimée pour chaque valeur de $M$ en utilisant la fonction `show_mixture` ci-dessous (inspirée du code de la [documentation scikit-learn](http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_pdf.html)).\n",
    "\n",
    "Constatez que l'évolution du critère BIC semble justifier que ce geyser présente deux \"modes de fonctionnement\". \n",
    "\n",
    "<br>\n",
    "\n",
    "_Remarque 1_ : $M$ est appelé un _hyperparamètre_ du modèle car il doit être fixé par l'utilisateur, à l'aide d'indicateurs comme BIC ici. Les paramètres du modèle sont les poids, moyennes, et matrices de covariance: ils sont estimés à partir des données par la fonction `fit` ci-dessous (qui, ici, met en oeuvre l'algorithme EM).\n",
    "\n",
    "_Remarque 2_ : par définition, la log-vraisemblance calculée à partir d'une observation (ce qui est retourné par `score_samples` ci-dessous) est le logarithme de la valeur de la densité de probabilité en cette observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mixture(mixture,X_train):\n",
    "    # mixture: objet GaussianMixture ajusté à des données\n",
    "    # X_train: pour le scatter-plot, observations sous forme d'un tableau (observations en lignes, caractéristiques en colonnes)\n",
    "    x = np.linspace(1, 5.5)\n",
    "    y = np.linspace(20., 120.)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "    Z = -mixture.score_samples(XX)  # score_samples est le log de la densité (log-vraisemblance) en chaque point  \n",
    "    Z = Z.reshape(X.shape)\n",
    "    plt.figure(figsize=[8,6])\n",
    "    CS = plt.contour(X, Y, Z, norm=LogNorm(vmin=1.0, vmax=100.0),\n",
    "                    levels=np.logspace(0, 3, 10))   # lignes d'iso-valeur\n",
    "    CB = plt.colorbar(CS, shrink=0.8, extend='both')\n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1])  # nuage des observations\n",
    "    plt.scatter(mixture.means_[:,0],mixture.means_[:,1],c='red')  # moyennes des composantes en rouge\n",
    "    plt.title('Level lines of negative log-likelihood predicted by a GMM, K='+str(mixture.n_components))\n",
    "    plt.axis('tight')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# votre code ici\n",
    "\n",
    "# exemple de code permettant de déterminer les paramètres d'un mélange à 4 composantes gaussiennes:\n",
    "GMM = mixture.GaussianMixture(n_components=4)\n",
    "GMM.fit(data[:,1:3])   # estimation des paramètres du mélange  (dans l'écriture Python 1:3, 3 est exclu)\n",
    "show_mixture(GMM,data[:,1:3])   # pour tracer les courbes de niveau de ce mélange\n",
    "print(GMM.bic(data[:,1:3]))  # affiche la valeur de BIC sur le jeu de données d'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__. Ecrivez les paramètres (poids, moyennes, matrices de covariance) du mélange de gaussienne optimal au sens de BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre code ici (affichez les paramètres du \"meilleur\" mélange)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3__. La \"méthode du coude\" de $K$-Means permet-elle de justifier un classification en deux groupes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre code ici\n",
    "# voir le code de l'exercice 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration de la théorie développée au chapitre 4, section 4.1.1\n",
    "\n",
    "## Prédiction du temps avant la prochaine éruption par Gaussian mixture regression\n",
    "\n",
    "Nous allons à présent prédire le temps d'attente avant la prochaine éruption en fonction de la durée d'une éruption.\n",
    "\n",
    "Si $x$ désigne la durée d'une éruption et $y$ le temps avant la prochaine éruption, nous venons de modéliser la densité $p(x,y)$ de la loi de probabilité jointe de $x$ et $y$ comme un mélange de deux gaussiennes.\n",
    "\n",
    "Nous verrons lors de la prochaine séance (polycopié chapitre 4, section 4.1.1) que la meilleure prédiction (en un sens précis) de $y$ en fonction de $x$ est donnée par l'espérance conditionnelle suivante:\n",
    "$$ h(x) = E(y|x) = \\int_y y p(y|x) dy$$\n",
    "Il s'agit de l'espérance de $y$ connaissant $x$. Autrement dit, il s'agit de la valeur moyenne de $y$ à $x$ fixé.\n",
    "\n",
    "Par définition,\n",
    "$$p(y|x) = \\frac{p(x,y)}{p(x)}$$\n",
    "et la densité marginale $p(x)$ est déterminée par:\n",
    "$$ p(x) = \\int_y p(x,y) dy$$\n",
    "Malheureusement, `GaussianMixture` de scikit-learn n'implémente pas ces calculs. Nous allons donc déterminer l'espérance conditionnelle $h(x)$ par intégration numérique, à partir du mélange de gaussiennes $p(x,y)$.\n",
    "\n",
    "C'est ce que fait la fonction `GMM_regression` dans la cellule suivante: ses arguments sont 1) un objet `GaussianMixture` représentant un mélange de Gaussiennes, et 2) un tableau de données $x$; elle retourne le tableau des valeurs prédites pour les valeurs de $x$ fournies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_regression(GMM,x):\n",
    "    y = np.linspace(20., 120.,num=1001)  # y discrétisé entre 20 et 120 par pas de 0.1 (1001 valeurs)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    XX = np.array([X.ravel(), Y.ravel()]).T\n",
    "    p = np.exp(GMM.score_samples(XX))   # score_samples fournit la log-vraisemblance d'une observation, p est donc bien la valeur de la densité  \n",
    "    p = p.reshape(X.shape)  # on construit ainsi la carte des p(x,y)\n",
    "    condexp = np.sum(Y*p,axis=0)/np.sum(p,axis=0)  # espérance conditionnelle obtenue par intégration numérique (ici, le première axe correspond à y)\n",
    "    return condexp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4__. Complétez le code suivant de manière à tracer le graphique de la prédiction du temps entre éruptions en fonction de la durée d'éruption.\n",
    "\n",
    "Comparez votre prédiction avec ce qui est proposé sur __[cette page](https://www.nps.gov/teachers/classrooms/predict-old-faithful.htm)__ du National Park Service. (nos données sont un peu ancienne, le \"fonctionnement\" du geyser évolue au fil des années)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMM=mixture.GaussianMixture(n_components=2,covariance_type='full')\n",
    "GMM.fit(data[:,1:3])\n",
    "x = np.linspace(1, 5.5)\n",
    "\n",
    "# votre code ici\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5__. Tracez la droite de régression linéaire superposée à l'estimation par espérance conditionnelle dans laquelle la loi jointe $p(x,y)$ est supposée gaussienne (il suffit de faire `n_components=1` dans `GaussianMixture`), et constatez que les prédictions sont identiques. La raison est expliquée dans la section du polycopié consacrée à la régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# votre code ici\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
