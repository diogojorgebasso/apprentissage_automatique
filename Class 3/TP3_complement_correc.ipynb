{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'apprentissage automatique: complément facultatif <font color=red> - CORRECTION </font>\n",
    "\n",
    "<br>\n",
    "\n",
    "## Complément facultatif: génération aléatoire d'images de chiffres manuscrits selon un mélange de gaussiennes\n",
    "\n",
    "\n",
    "On change de base de données pour utiliser:\n",
    "```python\n",
    "digits = datasets.load_digits()\n",
    "X_train2 = digits.data\n",
    "y_train2 = digits.target \n",
    "``` \n",
    "Cette base est formée de 1797 images de taille 8 pixels par 8 pixels. La dimension des observations (64) est donc bien plus faible que dans la base MNIST, ce qui rend les calculs moins longs et les modèles moins sujets à la malédiction de la dimension.\n",
    "\n",
    "Modélisez la distribution des chiffres manuscrits comme un mélange de gaussienne:\n",
    "* vous utiliserez un nombre de composantes minimisant le critère AIC (testez entre 1 et 200 composantes par pas de 20 pour limiter le temps de calcul)\n",
    "* vous représenterez les moyennes des composantes comme une image, en vous inspirant de la fonction d'affichage précédente (constatez que certains chiffres sont représentés par plusieurs gaussiennes)\n",
    "* vous générerez aléatoirement 100 chiffres avec cette méthode. Vous les représenterez, et vous les comparerez à 100 chiffres de la base.\n",
    "\n",
    "\n",
    "Si vous avez des résultats intéressants, n'hésitez pas à discuter vos résultats avec votre chargé de TD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture, datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_train2 = digits.data\n",
    "y_train2 = digits.target\n",
    "print(len(X_train2))\n",
    "size_images=(8,8)\n",
    "\n",
    "tab_AIC = []\n",
    "for K in range(1,201,20):\n",
    "    print(\"\\nnombre composantes: %d\" %K)\n",
    "    GMM = mixture.GaussianMixture(n_components=K, covariance_type=\"full\")\n",
    "    %time GMM.fit(X_train2)\n",
    "    AIC = GMM.aic(X_train2)\n",
    "    tab_AIC.append(AIC)\n",
    "    print(\"AIC: %d\" %AIC)\n",
    "\n",
    "tab_K=np.array(range(1,201,20))\n",
    "plt.figure()\n",
    "plt.plot(tab_K,tab_AIC)\n",
    "print(\"valeur de K minimisant AIC (à 20 près): K=%d\" %tab_K[np.argmin(tab_AIC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=120  # K réalisant le minimum de AIC (ou K=100, selon les exécutions)\n",
    "# faites aussi l'expérience avec K=10: chaque chiffre est représenté par une classe du mélange (voir les moyennes),\n",
    "# mais la génération aléatoire est bien moins réaliste car chaque chiffre ne peut pas être représenté de \n",
    "# manière satisfaisante par une unique gaussienne\n",
    "\n",
    "\n",
    "GMM=mixture.GaussianMixture(n_components=K, covariance_type='full')  \n",
    "%time GMM.fit(X_train2)  # EM\n",
    "\n",
    "# Représentation des moyennes du mélange:\n",
    "plt.figure(figsize=[15,12])    \n",
    "for n in range(K):\n",
    "   plt.subplot(10,12,n+1,xticks=[],yticks=[])\n",
    "   plt.imshow(np.reshape(GMM.means_[n,:],size_images),cmap='gray_r',vmin=0,vmax=16)\n",
    "plt.suptitle('moyennes des composantes du mélange de gaussiennes')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 100 chiffres générés aléatoirement:\n",
    "%time data_new_X, data_new_y = GMM.sample(100)\n",
    "plt.figure(figsize=[15,12])    \n",
    "for n in range(100):\n",
    "   plt.subplot(10,10,n+1,xticks=[],yticks=[])\n",
    "   plt.imshow(np.reshape(data_new_X[n,:],size_images),cmap='gray_r',vmin=0,vmax=16)\n",
    "   #plt.text(0.1,0.1,data_new_y[n],fontsize=6,bbox=dict(facecolor='white', alpha=1))\n",
    "plt.suptitle('100 chiffres synthétisés aléatoirement')\n",
    "plt.show()\n",
    "\n",
    "# à comparer aux 100 premiers chiffres de la base:\n",
    "plt.figure(figsize=[15,12])    \n",
    "for n in range(100):\n",
    "   plt.subplot(10,10,n+1,xticks=[],yticks=[])\n",
    "   plt.imshow(np.reshape(X_train2[n,:],size_images),cmap='gray_r',vmin=0,vmax=16)\n",
    "plt.suptitle('les 100 premiers chiffres issus de la base de données (pour comparaison)')\n",
    "plt.show();\n",
    "\n",
    "# Les chiffres synthétiques générés à partir d'un mélange de 120 gaussiennes ressemblent \n",
    "# plutôt bien aux vrais chiffres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On peut pousser la vérification du réalisme de la synthèse de chiffres \n",
    "# en faisant une classification des chiffres synthétiques \n",
    "# (par exemple avec KNN) et vérifier si la classe identifiée est plausible:\n",
    "\n",
    "from sklearn import neighbors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (on adapte affichage_150_images du TD précédent)\n",
    "def affichage_100_images(X_test,y_pred):\n",
    "    plt.figure(figsize=[15,12])   \n",
    "    for n in range(100):\n",
    "        plt.subplot(10,10,n+1,xticks=[],yticks=[])\n",
    "        plt.imshow(np.reshape(X_test[n,:],size_images),cmap='gray_r',vmin=0,vmax=16)\n",
    "        plt.text(0.1,0.1,str(y_pred[n]),fontsize=8,bbox=dict(facecolor='red', alpha=1))    \n",
    "    plt.suptitle('classe predite / classe réelle')\n",
    "    plt.show();\n",
    "    \n",
    "# classification au plus proche voisin et affichage\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1, n_jobs=12) \n",
    "knn.fit(X_train2, y_train2)\n",
    "y_pred_nn = knn.predict(data_new_X)\n",
    "affichage_100_images(data_new_X,y_pred_nn)\n",
    "# le résultat est plutôt convaincant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
