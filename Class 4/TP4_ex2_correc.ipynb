{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'apprentissage automatique: TP4 - Exercice 2 - <font color=red> CORRECTION </font>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Reconnaissance d'images par SVM: la base de données Fashion-MNIST\n",
    "\n",
    "<br>\n",
    "\n",
    "Dans cet exercice, on travaille sur la base de données Fashion-MNIST, qui a l'\"avantage\" de fournir un problème de classification plus difficile que la base MNIST du TP précédent.\n",
    "\n",
    "Commencez par lire la description de la base ici: https://www.openml.org/d/40996\n",
    "\n",
    "Pour limiter les temps de calcul pendant le TP, nous allons nous limiter aux 10000 premières images de la base. La cellule suivante charge les données et prépare une base d'apprentissage et une base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model, metrics, model_selection\n",
    "%matplotlib inline \n",
    "\n",
    "# Fashion-Mnist database sur openML: (il faut une dizaine de secondes pour charger la base)\n",
    "size_images=(28,28)\n",
    "X_fashion, y_fashion = datasets.fetch_openml(data_id=40996, return_X_y=True, as_frame=False, parser='auto')\n",
    "X_fashion=X_fashion[:10000,:]/255.  # normalisation des niveaux de gris entre 0 et 1\n",
    "y_fashion=y_fashion[:10000]\n",
    "\n",
    "for i in range(10):\n",
    "    n=np.sum(y_fashion==str(i))\n",
    "    print(\"nombre d'observations dans la classe %d: %d\" %(i,n))\n",
    "\n",
    "n_samples = len(X_fashion)\n",
    "print(\"nombre total d'observations (apprentissage + test): %d\" % n_samples)\n",
    "\n",
    "n_features = len(X_fashion[0])\n",
    "print(\"nombre de caractéristiques par observation: %d\" % n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_fashion, y_fashion, test_size=0.2, random_state=1)\n",
    "\n",
    "print(\"nombre d'observations dans la base d'apprentissage: %d\" %len(X_train))\n",
    "print(\"nombre d'observations dans la base de test: %d\" %len(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante définit une fonction qui permet d'afficher les 150 premières images de la base de test, ainsi que la classe $c$ déterminée par l'algorithme de classification et la classe véritable $c'$ sous la forme $c/c'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affichage_150_images(X_test,y_test,y_pred):\n",
    "    plt.figure(figsize=[15,12])   \n",
    "    for n in range(150):\n",
    "        plt.subplot(10,15,n+1,xticks=[],yticks=[])\n",
    "        plt.imshow(np.reshape(X_test[n,:],size_images),cmap='gray_r')\n",
    "        if y_pred[n]==y_test[n]:\n",
    "            plt.text(0.1,0.1,str(y_pred[n])+' / '+str(y_test[n]),fontsize=8,bbox=dict(facecolor='white', alpha=1))    \n",
    "        else:\n",
    "            plt.text(0.1,0.1,str(y_pred[n])+' / '+str(y_test[n]),fontsize=8,bbox=dict(facecolor='red', alpha=1))    \n",
    "    plt.suptitle('classe predite / classe réelle')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Questions__:\n",
    "\n",
    "Testez les classifieurs SVM à noyau linéaire et à noyau RBF. Pour vous éviter le temps de calcul de `GridSearchCV` (plusieurs minutes ici, étant donnée la taille de la base d'apprentissage):\n",
    "- pour le noyau linéaire, vous utiliserez la valeur $C=0.1$ \n",
    "- pour le noyau RBF, vous utiliserez la valeur de $\\gamma$ par défaut et $C=10$.\n",
    "\n",
    "Comparez les scores de classification sur la base de test de ces classifieurs aux scores de l'algorithme du plus proche voisin, des 5 plus proches voisins, à la classification bayésienne naïve gaussienne, et à la régression logistique (voir l'exercice 2 du TP3). Remarquez les bonnes performances des classifieurs linéaires, la mauvaise performance de GNB, et expliquez-les par les éléments du cours.\n",
    "\n",
    "Comparez également les temps de calcul: ajoutez `%time` (il s'agit d'une _magic command_ jupyter) devant les lignes où vous exécutez `fit` et `predict̀`). \n",
    "\n",
    "Vous obtenez l'indication Wall qui est la durée réellement écoulée sur une horloge murale (_wall clock_), ainsi que la valeur \"CPU\" qui compte le temps de calcul total sur le CPU (en additionnant le temps de processus s'exécutant en parallèle sur les coeurs du processeurs). Comme tous les modèles de prédiction de `scikit-learn` ne bénéficient pas de la parallélisation sur plusieurs coeurs, seuls les temps d'exécution \"CPU\" sont réellement comparables.\n",
    "\n",
    "\n",
    "Vous lirez dans la correction (à venir) une discussion sur le rôle des vecteurs supports (__facultatif__). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, model_selection, neighbors, naive_bayes, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facultatif: gridsearch pour SVM linear\n",
    "# attention, peut prendre plusieurs minutes (on se contente des valeurs de l'énoncé pendant le TP)\n",
    "\n",
    "C_range=10**(np.arange(-2.,2.5,1)) \n",
    "parameters = {'C': C_range }\n",
    "SVM1 = svm.SVC(kernel='linear')\n",
    "gridsearch1 = model_selection.GridSearchCV(SVM1, parameters,n_jobs=-1)\n",
    "%time gridsearch1.fit(X_train,y_train)\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch1.best_estimator_)\n",
    "print(\"Meilleur paramètre:\")\n",
    "print(gridsearch1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facultatif: gridsearch pour SVM RBF\n",
    "# attention, peut prendre plusieurs minutes (on se contente des valeurs de l'énoncé pendant le TP)\n",
    "\n",
    "C_range=10**(np.arange(-2.,2.5,1)) \n",
    "parameters = {'C': C_range }\n",
    "SVM2 = svm.SVC(kernel='rbf')\n",
    "gridsearch2 = model_selection.GridSearchCV(SVM2, parameters,n_jobs=-1)\n",
    "%time gridsearch2.fit(X_train,y_train)\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch2.best_estimator_)\n",
    "print(\"Meilleur paramètre:\")\n",
    "print(gridsearch2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM linear\n",
    "print('SVM linear\\n')\n",
    "SVM1 = svm.SVC(kernel='linear',C=0.1)\n",
    "%time SVM1.fit(X_train, y_train)\n",
    "%time y_pred_svm1 = SVM1.predict(X_test)\n",
    "\n",
    "print('SVM1 score: %f' % metrics.accuracy_score(y_test, y_pred_svm1))\n",
    "\n",
    "affichage_150_images(X_test,y_test,y_pred_svm1)        \n",
    "\n",
    "print(metrics.classification_report(y_test,y_pred_svm1))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred_svm1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM rbf\n",
    "print('SVM rbf\\n')\n",
    "SVM2 = svm.SVC(kernel='rbf', C=10)\n",
    "%time SVM2.fit(X_train, y_train)\n",
    "%time y_pred_svm2 = SVM2.predict(X_test)\n",
    "\n",
    "print('SVM2 score: %f' % metrics.accuracy_score(y_test, y_pred_svm2))\n",
    "\n",
    "affichage_150_images(X_test,y_test,y_pred_svm2)        \n",
    "\n",
    "print(metrics.classification_report(y_test,y_pred_svm2))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred_svm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification au plus proche voisin\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1, n_jobs=-1) \n",
    "%time knn.fit(X_train, y_train)\n",
    "%time y_pred_nn = knn.predict(X_test)\n",
    "\n",
    "print('KNN1 score: %f' % metrics.accuracy_score(y_test, y_pred_nn))\n",
    "\n",
    "affichage_150_images(X_test,y_test,y_pred_nn)        \n",
    "\n",
    "print(metrics.classification_report(y_test,y_pred_nn))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification aux 5 plus proche voisins\n",
    "knn5 = neighbors.KNeighborsClassifier(n_neighbors=5, n_jobs=-1) \n",
    "%time knn5.fit(X_train, y_train)\n",
    "%time y_pred_nn5 = knn5.predict(X_test)\n",
    "\n",
    "print('KNN5 score: %f' % metrics.accuracy_score(y_test, y_pred_nn5))\n",
    "\n",
    "affichage_150_images(X_test,y_test,y_pred_nn5)        \n",
    "\n",
    "print(metrics.classification_report(y_test,y_pred_nn5))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred_nn5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifieur naif de Bayes gaussien:\n",
    "NB = naive_bayes.GaussianNB()\n",
    "%time NBfit=NB.fit(X_train, y_train)\n",
    "%time y_pred_nb = NBfit.predict(X_test)\n",
    "\n",
    "print('score GNB: %.3f' % metrics.accuracy_score(y_test, y_pred_nb))\n",
    "    \n",
    "affichage_150_images(X_test,y_test,y_pred_nb)\n",
    "\n",
    "print(metrics.classification_report(y_test,y_pred_nb))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# régression logistique\n",
    "LR = linear_model.LogisticRegression(max_iter=5000, penalty=None)\n",
    "%time LR.fit(X_train, y_train)\n",
    "%time y_pred_lr=LR.predict(X_test)\n",
    "\n",
    "print('score LR: %3f' % metrics.accuracy_score(y_test, y_pred_lr))\n",
    "    \n",
    "affichage_150_images(X_test,y_test,y_pred_lr)\n",
    "\n",
    "print(metrics.classification_report(y_test,y_pred_lr))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    \n",
    "### Commentaires:\n",
    " \n",
    "On attend en réponse à cette question une discussion qualitative. On indique les scores sur la base test.\n",
    "    \n",
    "Les temps indiqués dépendent bien entendu du processeur.\n",
    "    \n",
    "Pour résumer (sur ma machine CPU Intel Core i7 @ 1.80GHz and 16 Gb memory):\n",
    "    \n",
    "### 1PPV\n",
    "\n",
    "entraînement Wall time: 9.52 ms\n",
    "\n",
    "prédiction Wall time: 615 ms\n",
    "\n",
    "KNN1 score: 0.816000\n",
    "\n",
    "### 5PPV\n",
    " \n",
    "entraînement Wall time: 25.1 ms\n",
    "    \n",
    "prédiction Wall time: 875 ms\n",
    "    \n",
    "KNN5 score: 0.833000\n",
    "    \n",
    "### GNB\n",
    "\n",
    "entraînement Wall time: 120 ms\n",
    "    \n",
    "prédiction Wall time: 170 ms\n",
    "    \n",
    "score GNB: 0.529\n",
    "  \n",
    "### LR\n",
    "\n",
    "entraînement Wall time: 23.2 s\n",
    "    \n",
    "prédiction Wall time: 5.02 ms\n",
    "    \n",
    "score LR: 0.770000\n",
    "   \n",
    "### SVM linear\n",
    " \n",
    "entraînement Wall time: 6.27 s\n",
    "    \n",
    "prédiction Wall time: 3.19 s\n",
    "    \n",
    "SVM1 score: 0.849500\n",
    "    \n",
    "### SVM RBF\n",
    "    \n",
    "entraînement Wall time: 8.12 s\n",
    "    \n",
    "prédiction Wall time: 28.1 s\n",
    "    \n",
    "SVM2 score: 0.878500\n",
    "\n",
    "<br>\n",
    "    \n",
    "Tout d'abord on constate que les classifieurs linéaires (SVM linear et LR) donnent de bonnes performances: cela correspond à la situation décrite dans le polycopié d'un problème de classification en grande dimension, pour lequel il est \"assez facile\" de séparer linéairement les classes. SVM linear donne un score meilleur que LR. Néanmoins, on voit que le classifieur non-linéaire SVM RBF permet une augmentation du score de prédiction. GNB a une performance très modeste: l'hypothèse d'indépendance conditionnelle des caractéristiques est trop grossière. En effet, les caractéristiques sont les valeurs des niveaux de gris en chaque pixel: on suppose donc dans GNB que, dans chaque classe, les pixels ne sont pas \"liés\" entre eux. Cette hypothèse est bien entendu en contradiction flagrante avec le fait que c'est la perception de groupes de pixels agencés les uns par rapport aux autres qui nous fait reconnaître une forme.\n",
    "    \n",
    "<br>\n",
    "    \n",
    "  \n",
    "Pour les deux SVM: \n",
    "- la classe 6 (chemises) a la moins bonne précision: certains vêtements sont reconnus comme des chemises à tort.\n",
    "- la classe 6 a également le moins bon rappel: certaines chemises sont reconnus comme d'autres vêtements à tort.\n",
    "\n",
    "On retrouve ce constat sur les matrices de confusion: \n",
    "- la colonne de 6 montre que des 0 (t-shirts) et 2 (pull-over) sont reconnus comme chemises\n",
    "- la ligne de 6 montre que des chemises sont reconnus comme des 0 (t-shirts), 2 (pull-over), 4 (manteau).\n",
    "    \n",
    "On voit sur la sortie de `affichage_150_images` que les erreurs correspondent effectivement à des cas où l'image est assez ambigüe.\n",
    "  \n",
    "<br> \n",
    "     \n",
    "_Complément_: Le temps d'entraînement des SVM est plus faible que pour LR (d'autant plus que LR est parallélisé sur tous les coeurs, contrairement aux SVM), mais la prédiction est bien plus rapide pour LR. La prédiction par LR consiste essentiellement à calculer un produit scalaire en dimension 28x28 par classe, alors que la prédiction par SVM nécessite de calculer pour chaque paire de classes (classification multi-classe one-vs-one pour SVC) une somme de $k(x_i,x)$ avec les $x_i$ vecteurs supports, ce qui est plus lourd dans cette expérience (ce n'est pas une vérité générale).\n",
    "\n",
    " \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion sur les vecteurs supports (facultatif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('nombre de vecteurs supports par classe et coefficients du dual:') \n",
    "print('\\nSVM linear')\n",
    "print('\\nnombre de vecteurs supports par classe:')\n",
    "print(SVM1.n_support_)\n",
    "print('\\ncoefficient duaux:')\n",
    "print(SVM1.dual_coef_)\n",
    "print('\\ndimension de la matrice des coefficients duaux:')\n",
    "print(SVM1.dual_coef_.shape)\n",
    "print('\\nnombre total de vecteurs supports')\n",
    "print(np.sum(SVM1.n_support_))\n",
    "print('\\n\\nSVM RBF')\n",
    "print('\\nnombre de vecteurs supports:')\n",
    "print(SVM2.n_support_)\n",
    "print(\"\\ncoefficient duaux (il s'agit de la valeur de y_i * lambda_i):\")\n",
    "print(SVM2.dual_coef_)\n",
    "print('\\ndimension de la matrice des coefficients duaux:')\n",
    "print(SVM2.dual_coef_.shape)\n",
    "print('\\nnombre total de vecteurs supports')\n",
    "print(np.sum(SVM2.n_support_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "\n",
    "__Complément facultatif: à propos des vecteurs supports__\n",
    "    \n",
    "<br>\n",
    "\n",
    "    \n",
    "Le noyau RBF fournit plus de vecteurs supports que le noyau linear. Cela explique les temps de prédiction plus longs pour RBF que pour linear, et peut-être aussi le temps d'entraînement plus long (mais cela dépend de l'algorithme d'optimisation utilisé: le nombre de vecteurs supports joue un rôle mais difficile d'en dire davantage).\n",
    "    \n",
    "<br>\n",
    "    \n",
    "Attention, le contenu de `dual_coef_` de `scikit-learn` est en fait la valeur de $y_i \\lambda_i$ dans le cours: les coefficients duals sont positifs par définition: une valeur négative dans la matrice `dual_coef_` signifie que le vecteur support a été associé à la classe -1.\n",
    "    \n",
    "On voit que les vecteurs supports ne sont pas répartis uniformément entre les classes. Globalement les classes 0, 2, 4, 6 nécessitent le plus de vecteurs support, et 1, 7, 8, 9 le moins de vecteurs supports (pour les deux noyaux). Intuitivement, si une classe nécessite beaucoup de vecteurs supports, c'est qu'elle est difficile à discriminer d'au moins une autre classe, il  faut alors la représenter par plus de vecteurs (rappelons que les vecteurs \"non-supports\" n'interviennent pas dans la prédiction). Il s'agit d'une discussion assez heuristique mais on peut aussi remarquer que les classes 2,4,6 ont le moins bon f1-score (elles semblent effectivement difficile à représenter), et la classe 1 le meilleur f1-score.\n",
    "    \n",
    "Si on est curieux, on peut se demander ce que sont les vecteurs supports dans un problème de classification multiclasses. On sait qu'en fait c'est une stratégie one-vs-one qui est implantée par `SVC`: une SVM est entraînée par couple de classes. Chaque classe doit donc avoir 9 listes de vecteurs supports (une liste par classe alternative). L'attribut `dual_coef_` contient la liste des 9 coefficients duals (duaux ?) des vecteurs supports: 9 car chaque coefficient est fourni par une SVM one-vs-one. Les vecteurs supports comptés par `n_support` sont ceux qui sont vecteurs supports d'__au moins une SVM__, pour lequel le coefficient dual correspondant est non nul. On voit qu'une observation n'est généralement pas vecteur support de plus d'une SVM (le coefficient dual est généralement nul sauf dans un cas). \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
