{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'apprentissage automatique - TP4 exercice 3 - <font color=red> CORRECTION </font>\n",
    "\n",
    "### SVM sur données réelles\n",
    "\n",
    "<br> \n",
    "\n",
    "On considère le jeu de données `breast-cancer` décrit __[ici](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)__ et __[là](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))__. \n",
    "\n",
    "__Questions__.  Que contient ce jeu de données? Combien d'observations et d'attributs par observation? Que cherche-t-on à prédire?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "\n",
    "Une observation correspond à une image d'un groupe de cellules. \n",
    "Pour chaque cellule, 10 caractéristiques sont calculées. \n",
    "Pour une observation, les moyennes, écarts-types, et maximum des 10 caractéristiques associées aux cellules visibles dans l'image sont calculées.\n",
    "\n",
    "Chacune des 569 observations est donc décrite par 30 caractéristiques.\n",
    "    \n",
    "Les étiquettes sont 1 (tumeur bénigne) et 0 (tumeur maligne)\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Réservez 20% des observations pour former une base de test.\n",
    "\n",
    "__Travail à faire__. Mettez en oeuvre la classification par une SVM à noyau gaussien (gardez la valeur par défaut \"scale\" pour le paramètre `gamma`) et une SVM linéaire ainsi que les autres méthodes de classification que vous connaissez bien à présent.\n",
    "\n",
    "Vous comparerez les scores de classification avec et sans normalisation ( _standardisation_ : les caractéristiques sont centrées et réduites). Vous fixerez les hyperparamètres de ces méthodes par validation croisée sur la base d'apprentissage, et vous comparerez les performances des méthodes sur la base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics, model_selection, preprocessing, neighbors, naive_bayes, linear_model, svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# on charge le jeu de données et on garde 30% comme base test:\n",
    "dataset = datasets.load_breast_cancer()\n",
    "X_dataset = dataset.data\n",
    "y_dataset = dataset.target\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_dataset,y_dataset,test_size=.2,random_state=1)\n",
    "\n",
    "print(\"Les 3 premières observations (non normalisées):\")\n",
    "print(X_train[:3,:])\n",
    "\n",
    "print(\"et les étiquettes:\")\n",
    "print(y_train[:3])\n",
    "\n",
    "# normalisation:\n",
    "X_train_n = preprocessing.StandardScaler().fit_transform(X_train)\n",
    "X_test_n = preprocessing.StandardScaler().fit(X_train).transform(X_test)\n",
    "\n",
    "print(\"\\nLes 3 premières observations (normalisées):\")\n",
    "print(X_train_n[:3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choix de C pour SVM et noyau gaussien  \n",
    "# on garde le coef gamma fixé par défaut\n",
    "C_range=10**(np.arange(-6.,6.5,1))   \n",
    "parameters = { 'C':C_range }\n",
    "SVM = svm.SVC(kernel='rbf')\n",
    "\n",
    "gridsearch = model_selection.GridSearchCV(SVM, parameters,n_jobs=-1)\n",
    "\n",
    "# sans normalisation:\n",
    "print('données non normalisées\\n')\n",
    "%time gridsearch.fit(X_train,y_train)\n",
    "plt.figure()\n",
    "plt.semilogx(C_range,gridsearch.cv_results_['mean_test_score'])  \n",
    "plt.grid()\n",
    "plt.show()\n",
    "# on voit sur ce graphique qu'on aurait pu prendre C=10^3 ou C=10^5 sans changer beaucoup le score\n",
    "# (une autre séparation train/test de la base aurait pu conduire à sélectionner ces valeurs)\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# avec normalisation:\n",
    "print('données normalisées\\n')\n",
    "%time gridsearch.fit(X_train_n,y_train)\n",
    "plt.figure()\n",
    "plt.semilogx(C_range,gridsearch.cv_results_['mean_test_score'])  \n",
    "plt.grid()\n",
    "plt.show()\n",
    "# même remarque: C=10 aurait pu être choisi\n",
    "print(\"Avec normalisation, meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Avec normalisation, meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choix de C pour SVM linéaire\n",
    "C_range=10**(np.arange(-6.,6.5,1))   \n",
    "parameters = { 'C':C_range }\n",
    "SVM2 = svm.SVC(kernel='linear')\n",
    "\n",
    "gridsearch = model_selection.GridSearchCV(SVM2, parameters,n_jobs=-1)\n",
    "\n",
    "# sans normalisation:\n",
    "print('données non normalisées\\n')\n",
    "%time gridsearch.fit(X_train,y_train)\n",
    "plt.figure()\n",
    "plt.semilogx(C_range,gridsearch.cv_results_['mean_test_score'])  \n",
    "plt.grid()\n",
    "plt.show()\n",
    "# on voit sur ce graphique qu'on aurait pu prendre C=10^3 ou C=10^5 sans changer beaucoup le score\n",
    "# (une autre séparation train/test de la base aurait pu conduire à sélectionner ces valeurs)\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# avec normalisation:\n",
    "print('données normalisées\\n')\n",
    "%time gridsearch.fit(X_train_n,y_train)\n",
    "plt.figure()\n",
    "plt.semilogx(C_range,gridsearch.cv_results_['mean_test_score'])  \n",
    "plt.grid()\n",
    "plt.show()\n",
    "# même remarque: C=10 aurait pu être choisi\n",
    "print(\"Avec normalisation, meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Avec normalisation, meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_range=[1, 2, 5, 10, 15, 20, 25]\n",
    "parameters = {'n_neighbors': K_range}\n",
    "KNN = neighbors.KNeighborsClassifier()\n",
    "gridsearch = model_selection.GridSearchCV(KNN, parameters, n_jobs=-1)\n",
    "\n",
    "# sans normalisation:\n",
    "print('données non normalisées\\n')\n",
    "%time gridsearch.fit(X_train,y_train)\n",
    "plt.figure()\n",
    "plt.semilogx(K_range,gridsearch.cv_results_['mean_test_score'])  \n",
    "plt.grid()\n",
    "plt.show()\n",
    "# on voit que le score moyen varie très peu, la sélection est assez arbitraire\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# avec normalisation:\n",
    "print('données normalisées\\n')\n",
    "%time gridsearch.fit(X_train_n,y_train)\n",
    "plt.figure()\n",
    "plt.semilogx(K_range,gridsearch.cv_results_['mean_test_score'])  \n",
    "plt.grid()\n",
    "plt.show()\n",
    "# idem\n",
    "print(\"Avec normalisation, meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Avec normalisation, meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_range=10**(np.arange(-6.,6.5,1))   \n",
    "parameters = {'C': C_range}\n",
    "LR = linear_model.LogisticRegression()\n",
    "gridsearch = model_selection.GridSearchCV(LR, parameters, n_jobs=-1)\n",
    "\n",
    "# sans normalisation:\n",
    "print('données non normalisées\\n')\n",
    "%time gridsearch.fit(X_train,y_train)\n",
    "plt.figure()\n",
    "plt.semilogx(C_range,gridsearch.cv_results_['mean_test_score'])  \n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(\"Meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# avec normalisation:\n",
    "print('données normalisées\\n')\n",
    "%time gridsearch.fit(X_train_n,y_train)\n",
    "plt.figure()\n",
    "plt.semilogx(C_range,gridsearch.cv_results_['mean_test_score'])  \n",
    "plt.grid()\n",
    "plt.show()\n",
    "print(\"Avec normalisation, meilleur estimateur trouvé:\")\n",
    "print(gridsearch.best_estimator_)\n",
    "print(\"Avec normalisation, meilleurs paramètres:\")\n",
    "print(gridsearch.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remarque: les valeurs des hyperparamètres sélectionnés peuvent varier d'une exécution à l'autre\n",
    "# ce n'est pas étonnant vu que plusieurs valeurs sont proches du maximum dans les graphes précédents\n",
    "# et que ces graphes varient d'une exécution à l'autre de la validation croisée (choix aléatoire des plis)\n",
    "\n",
    "print(\"Scores sur la base test:\\n\")\n",
    "\n",
    "print(\"Sans normalisation:\")\n",
    "\n",
    "print(\"SVM-gaussian\")\n",
    "SVM=svm.SVC(kernel='rbf',C=10000)  \n",
    "SVM.fit(X_train,y_train)\n",
    "print(\"score SVM-gaussien %.3f\" % SVM.score(X_test, y_test) )\n",
    "\n",
    "print(\"SVM-linear\")\n",
    "SVM2=svm.SVC(kernel='linear',C=0.01)  \n",
    "SVM2.fit(X_train,y_train)\n",
    "print(\"score SVM-linear %.3f\" % SVM2.score(X_test, y_test) )\n",
    "\n",
    "print(\"15-NN\")\n",
    "NN10 = neighbors.KNeighborsClassifier(n_neighbors=15)   \n",
    "NN10.fit(X_train,y_train)\n",
    "print(\"score NN15 %.3f\" % NN10.score(X_test, y_test) )\n",
    "\n",
    "print(\"NB\")\n",
    "NB = naive_bayes.GaussianNB()\n",
    "NB.fit(X_train,y_train)\n",
    "print(\"score NB %.3f\" % NB.score(X_test, y_test) )\n",
    "\n",
    "print(\"LR\")\n",
    "LR = linear_model.LogisticRegression(C=10,max_iter=5000)\n",
    "LR.fit(X_train,y_train)\n",
    "print(\"score LR %.3f\" % LR.score(X_test, y_test) )\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Avec normalisation:\")\n",
    "\n",
    "print(\"SVM-gaussian\")\n",
    "SVM=svm.SVC(kernel='rbf',C=1)  \n",
    "SVM.fit(X_train_n,y_train)\n",
    "print(\"score SVM-gaussian %.3f\" % SVM.score(X_test_n, y_test) )\n",
    "\n",
    "print(\"SVM-linear\")\n",
    "SVM2=svm.SVC(kernel='linear',C=0.1)  \n",
    "SVM2.fit(X_train_n,y_train)\n",
    "print(\"score SVM-linear %.3f\" % SVM2.score(X_test_n, y_test) )\n",
    "\n",
    "print(\"5-NN\")\n",
    "NN10 = neighbors.KNeighborsClassifier(n_neighbors=10)   \n",
    "NN10.fit(X_train_n,y_train)\n",
    "print(\"score NN5 %.3f\" % NN10.score(X_test_n, y_test) )\n",
    "\n",
    "print(\"NB\")\n",
    "NB = naive_bayes.GaussianNB()\n",
    "NB.fit(X_train_n,y_train)\n",
    "print(\"score NB %.3f\" % NB.score(X_test_n, y_test) )\n",
    "\n",
    "print(\"LR\")\n",
    "LR = linear_model.LogisticRegression(C=0.1)\n",
    "LR.fit(X_train_n,y_train)\n",
    "print(\"score LR %.3f\" % LR.score(X_test_n, y_test) )\n",
    "\n",
    "# meilleur prédiction pour LR (ou SVM) + normalisation:\n",
    "\n",
    "print(\"\\n\\nmeilleures prédictions:\")\n",
    "print(\"\\nmatrice de confusion LR + normalisation:\")\n",
    "print(metrics.confusion_matrix(y_test, LR.predict(X_test_n))) \n",
    "# attention au codage 0/1 des classes: 3 observations ont été classées comme 1 (tumeur bénigne à tort)\n",
    "# La documentation parle de faux positif pour cet élément de la matrice de confusion, \n",
    "# mais cela dépend du point de vue et de ce qu'on considère comme \"positif\": \n",
    "# ici on ne détecte pas le cancer, mais le caractère bénin (classe 1)\n",
    "print(\"\\nmatrice de confusion SVM RBF + normalisation:\")\n",
    "print(metrics.confusion_matrix(y_test, SVM.predict(X_test_n)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "\n",
    "_Remarque_: la standardisation améliore les performance des classifieurs, mais aussi les temps d'apprentissage et prédiction.  Standardiser les données améliore le comportement des algorithmes d'optimisation numérique ou de recherche de plus proche voisin.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
