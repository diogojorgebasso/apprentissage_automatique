{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'apprentissage automatique: TP1 - Exercice 2 \n",
    "\n",
    "<br>\n",
    "\n",
    "L'objectif de cet exercice est de construire un modèle de régression linéaire.\n",
    "\n",
    "__Remarque__: il ne s'agit que d'une étude préliminaire; il faudrait également tester les modèles non-linéaires que l'on verra dans la suite du cours.\n",
    "\n",
    "<br>\n",
    "\n",
    "On cherche à prédire l'influence de dix indicateurs $x_1,x_2,\\dots,x_{10}$ (âge, sexe, et diverses mesures physiologiques) sur un indicateur $y$ de la progression du diabète, à l'aide d'un modèle linéaire. Une étude complète nécessiterait de justifier ce modèle par des graphiques, les coefficients de corrélation linéaire, etc., comme vous l'avez fait en cours d'Analyse de données. Nous ne le ferons pas faute de temps.\n",
    "\n",
    "On se base sur un jeu de données intégré à scikit-learn et [décrit ici](https://scikit-learn.org/stable/datasets/toy_dataset.html#diabetes-dataset).\n",
    "\n",
    "Notez la remarque:\n",
    "> Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of n_samples (i.e. the sum of squares of each column totals 1).\n",
    "\n",
    "Il est donc inutile de normaliser les caractéristiques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des bibliothèques Python utiles:\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model, metrics, model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# \"magic function\" Jupyter pour l'affichage des graphiques dans le carnet:\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des données\n",
    "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "# affichage des 5 premières observations \n",
    "print(diabetes_X[:5,:])  # rappel: les observations ont été préalablement normalisées\n",
    "print(diabetes_y[:5])  # les labels y ne sont pas normalisés\n",
    "\n",
    "# nombre d'observations:\n",
    "print(\"\\nnombre d'observations dans la base de données: %d\" %len(diabetes_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les observations (chacune est composée de 10 indicateurs) forment les colonnes de `diabetes_X` et l'indicateur à prédire est stocké dans `diabetes_y`.\n",
    "\n",
    "On commence par séparer la base de données entre un ensemble d'apprentissage et un ensemble de test qui nous servira à évaluer les modèles de régression (20% des observations pour ce dernier ensemble). La répartition est faite de manière aléatoire par la cellule suivante. \n",
    "\n",
    "__Remarque__: dans la cellule suivante, `random_state=42` (nombre arbitraire) permet de fixer la graine du générateur aléatoire de manière à ce que nous ayons tous la même répartition aléatoire, ce qui facilitera la discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(diabetes_X, diabetes_y, \\\n",
    "    test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1__. Que font les trois cellules suivantes? Commentez en particulier les graphiques. Pourquoi la MSE est-elle calculée sur la base test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "MSE_lr = np.mean((lr.predict(X_test) - y_test) ** 2)\n",
    "\n",
    "print(MSE_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    \n",
    "Votre réponse.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 100\n",
    "alphas = np.logspace(-4, 4, n_alphas)\n",
    "coefs=np.zeros((0,10))\n",
    "MSE_ridge=[]\n",
    "for a in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=a)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    coefs=np.vstack((coefs,ridge.coef_))\n",
    "    MSE_ridge.append([MSE_lr, np.mean((ridge.predict(X_test) - y_test) ** 2)])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.semilogx(alphas, coefs)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('coefs')\n",
    "plt.title('Coefficients de la régression ridge en fonction de alpha')\n",
    "plt.axis('tight')\n",
    "plt.legend(['w1','w2','w3','w4','w5','w6','w7','w8','w9','w10'])\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.semilogx(alphas, MSE_ridge)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE régression linéaire et ridge vs. alpha ')\n",
    "plt.axis([1e-4,1e4,2750,5500])\n",
    "plt.legend(['MSE lr','MSE ridge'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    \n",
    "Votre réponse.\n",
    "\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 100\n",
    "alphas = np.logspace(-4, 4, n_alphas)\n",
    "coefs=np.zeros((0,10))\n",
    "MSE_lasso=[]\n",
    "for a in alphas:\n",
    "    lasso = linear_model.Lasso(alpha=a)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    coefs=np.vstack((coefs,lasso.coef_))\n",
    "    MSE_lasso.append([MSE_lr, np.mean((lasso.predict(X_test) - y_test) ** 2)])\n",
    "\n",
    "#print(coefs)\n",
    "    \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.semilogx(alphas, coefs)\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('coefs')\n",
    "plt.title('Coefficients du Lasso en fonction de alpha')\n",
    "plt.legend(['w1','w2','w3','w4','w5','w6','w7','w8','w9','w10'])\n",
    "plt.axis('tight')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.semilogx(alphas, MSE_lasso)\n",
    "plt.semilogx(alphas, MSE_ridge, '--')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('MSE')\n",
    "plt.axis([1e-4,1e4,2750,5500])\n",
    "plt.title('MSE régression linéaire, lasso, et ridge vs. alpha ')\n",
    "plt.legend(['MSE lr','MSE lasso','MSE ridge (rappel)'])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "    \n",
    "Votre réponse.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__. Proposez des modèles de régression multivariée pour prédire $y$ en fonction des 10 indicateurs dans $X$. Vous testerez régression linéaire, ridge, lasso et fixerez l'hyperparamètre de ces deux dernières méthodes par validation croisée sur la _base d'apprentissage_ , conformément à la démarche vue dans l'exercice 1 (utilisez `RidgeCV` et `LassoCV`).\n",
    "\n",
    "<br>\n",
    "\n",
    "Quel est finalement le meilleur modèle?  Quelles sont les variables sélectionnées et leur influence quantitative?\n",
    "\n",
    "_Indication_ : calculez la valeur de MSE sur la _base de test_ et comparez à la variance des étiquettes à prédire.\n",
    "\n",
    "<br>\n",
    "\n",
    "Quelles variables semblent les plus pertinentes dans l'étude?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# votre code ici:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>\n",
    "\n",
    "Votre réponse.\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
